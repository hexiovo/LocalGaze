import random
import cv2
import numpy as np
from typing import List, Tuple
import time

from eyetrax.calibration.common import (
    _pulse_and_capture,
    compute_grid_points,
    wait_for_face_and_countdown,
)
from eyetrax.utils.screen import get_screen_size


class BlueNoiseSampler:
    def __init__(self, w: int, h: int, margin: float = 0.08):
        self.w, self.h = w, h
        self.mx, self.my = int(w * margin), int(h * margin)

    def sample(self, n: int, k: int = 30) -> List[Tuple[int, int]]:
        pts: List[Tuple[int, int]] = []
        for _ in range(n):
            best, best_d2 = None, -1
            for _ in range(k):
                x = random.randint(self.mx, self.w - self.mx)
                y = random.randint(self.my, self.h - self.my)
                d2 = (
                    min((x - px) ** 2 + (y - py) ** 2 for px, py in pts) if pts else 1e9
                )
                if d2 > best_d2:
                    best, best_d2 = (x, y), d2
            pts.append(best)
        return pts

def run_9_point_calibration(gaze_estimator, camera_index: int = 0):
    """
    ä¹ç‚¹æ ¡å‡†ï¼Œå¸¦å®æ—¶æ³¨è§†ç‚¹æ¦‚ç‡äº‘æ˜¾ç¤º
    Returns:
        errors_per_point: æ¯ä¸ªæ ¡å‡†ç‚¹è¯¯å·®åˆ—è¡¨
        mean_error: å¹³å‡è¯¯å·®
    """

    sw, sh = get_screen_size()
    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print("æ‘„åƒå¤´æœªæˆåŠŸæ‰“å¼€")
        return None, None

    # å¦‚æœä¹‹å‰æœ‰ Tkinter å¼¹çª—ï¼Œç¡®ä¿é”€æ¯ï¼Œé¿å…é˜»å¡
    try:
        import tkinter as tk
        root = tk._default_root
        if root:
            root.update()
            root.destroy()
    except Exception:
        pass

    if not wait_for_face_and_countdown(cap, gaze_estimator, sw, sh, 2):
        cap.release()
        cv2.destroyAllWindows()
        return None, None

    order = [
        (1, 1),
        (0, 0),
        (2, 0),
        (0, 2),
        (2, 2),
        (1, 0),
        (0, 1),
        (2, 1),
        (1, 2),
    ]
    pts = compute_grid_points(order, sw, sh)

    # æ•è·ç‰¹å¾å’Œç›®æ ‡åæ ‡ï¼Œå®æ—¶æ˜¾ç¤ºæ¦‚ç‡äº‘
    res = _pulse_and_capture(gaze_estimator, cap, pts, sw, sh)

    # ç¡®ä¿é‡Šæ”¾æ‘„åƒå¤´å’Œçª—å£
    cap.release()
    cv2.destroyAllWindows()

    if res is None:
        return None, None

    feats, targs = res
    if feats:
        feats = np.array(feats)
        targs = np.array(targs)

        # è®­ç»ƒæ¨¡å‹
        gaze_estimator.train(feats, targs)

        # é¢„æµ‹è®­ç»ƒç‚¹
        preds = gaze_estimator.predict(feats)

        # æ¯å¸§è¯¯å·®
        errors_per_frame = np.linalg.norm(preds - targs, axis=1)

        # æŒ‰ç›®æ ‡ç‚¹åˆ’åˆ†ï¼Œæ¯ä¸ªç›®æ ‡ç‚¹å¯¹åº”çš„å¸§ç´¢å¼•
        unique_points, indices = np.unique(targs, axis=0, return_inverse=True)

        # å­˜å‚¨æ¯ä¸ªç‚¹çš„æ‰€æœ‰å¸§è¯¯å·®
        every_point_errors = [[] for _ in range(len(unique_points))]
        for frame_idx, point_idx in enumerate(indices):
            every_point_errors[point_idx].append(errors_per_frame[frame_idx])

        # è®¡ç®—æ¯ä¸ªç‚¹å¹³å‡è¯¯å·®
        errors_per_point = [np.mean(errors) if errors else np.nan for errors in every_point_errors]

        # æ€»å¹³å‡è¯¯å·®ï¼ˆæ‰€æœ‰å¸§è¯¯å·®çš„å¹³å‡ï¼‰
        mean_error = np.mean(errors_per_frame)

        print("Per-point average errors:", errors_per_point)
        print(f"Mean calibration error: {mean_error:.2f} pixels")

        return every_point_errors, mean_error

    return None, None


def run_additional_random_calibration(
    gaze_estimator,
    camera_index: int = 0,
    points_per_round: int = 5,
    error_threshold: float = 30.0,
    max_rounds: int = 10
):
    """
    éšæœºç‚¹è¡¥å……æ ¡å‡†æµç¨‹ï¼š
    - æ¯è½®é‡æ–°æ‰“å¼€æ‘„åƒå¤´å¹¶é‡‡é›†è‹¥å¹²ç‚¹ï¼›
    - è®¡ç®—æ¯ä¸ªç‚¹çš„é€å¸§è¯¯å·®ä¸æ¯è½®å¹³å‡è¯¯å·®ï¼›
    - è¿”å›ï¼š
        every_point_errors_per_round: list[list[np.ndarray]]ï¼Œæ¯è½®æ¯ç‚¹çš„å¸§è¯¯å·®
        mean_errors_per_round: list[float]ï¼Œæ¯è½®å¹³å‡è¯¯å·®
    """
    from eyetrax.calibration.adaptive import _pulse_and_capture_live
    import cv2, time
    import numpy as np

    sw, sh = get_screen_size()
    sampler = BlueNoiseSampler(sw, sh)

    round_count = 0
    current_mean_error = float('inf')

    every_point_errors_per_round = []  # æ¯è½®æ¯ç‚¹çš„è¯¯å·®å¸§
    mean_errors_per_round = []         # æ¯è½®å¹³å‡è¯¯å·®

    print("ğŸŸ¢ å¼€å§‹éšæœºè¡¥å……æ ¡å‡†...")

    while current_mean_error > error_threshold and round_count < max_rounds:
        round_count += 1
        print(f"\nâ€”â€” ç¬¬ {round_count} è½® â€”â€”")

        pts = sampler.sample(points_per_round)

        # æ¯è½®å•ç‹¬æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(camera_index)
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ã€‚")
            break

        try:
            res = _pulse_and_capture_live(
                gaze_estimator, cap, pts, sw, sh, show_real_time=True
            )
        except Exception as e:
            print(f"âš  ç¬¬ {round_count} è½®è¿è¡Œå‡ºé”™: {e}")
            res = None
        finally:
            cap.release()
            cv2.waitKey(200)
            cv2.destroyAllWindows()
            time.sleep(0.3)

        # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
        if not res or res[0] is None or len(res[0]) == 0:
            print(f"  âŒ ç¬¬ {round_count} è½®æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡ã€‚")
            mean_errors_per_round.append(np.nan)
            continue

        feats, targs = map(np.array, res)
        if feats.shape[0] == 0:
            print(f"  âš  ç¬¬ {round_count} è½®é‡‡é›†ä¸ºç©ºï¼Œç»§ç»­ä¸‹ä¸€è½®ã€‚")
            mean_errors_per_round.append(np.nan)
            continue

        # âœ… è®­ç»ƒå¹¶é¢„æµ‹
        gaze_estimator.train(feats, targs)
        preds = gaze_estimator.predict(feats)

        # âœ… è®¡ç®—é€å¸§è¯¯å·®
        errors_per_frame = np.linalg.norm(preds - targs, axis=1)

        # âœ… æŒ‰ç›®æ ‡ç‚¹èšç±»
        unique_points, indices = np.unique(targs, axis=0, return_inverse=True)
        every_point_errors = [errors_per_frame[indices == i] for i in range(len(unique_points))]

        # âœ… è®¡ç®—å¹³å‡è¯¯å·®
        errors_per_point = [np.mean(e) for e in every_point_errors if len(e) > 0]
        current_mean_error = np.nanmean(errors_per_point)

        # âœ… ä¿å­˜ç»“æœ
        every_point_errors_per_round.append(every_point_errors)
        mean_errors_per_round.append(current_mean_error)

        print(f"  âœ… å¹³å‡è¯¯å·® = {current_mean_error:.2f} åƒç´ ")

        if current_mean_error <= error_threshold:
            print(f"ğŸ¯ è¾¾åˆ°ç›®æ ‡ç²¾åº¦ï¼ˆå¹³å‡è¯¯å·® {current_mean_error:.2f}pxï¼‰ï¼Œç»“æŸæ ¡å‡†ã€‚")
            break

    print("\nâœ… éšæœºè¡¥å……æ ¡å‡†å®Œæˆã€‚")
    return every_point_errors_per_round, mean_errors_per_round




